---
title: "Отчёт по лабораторной работе №1 по дисциплине \"Статистическое моделирование\""
author: "Шайхльбарин Денис Маратович"
date: 'Выполнено: `r Sys.Date()`'
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
  word_document: default
mainfont: Arial
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setlocale("LC_CTYPE",  "English") 
Sys.setlocale("LC_CTYPE",  "Russian") 
```

```{r}
library(ggplot2)
library(memisc)
library(DescTools)
library(broom)
library(caTools)
library(lmtest)
library(dplyr)
library(readxl)

```



## Самостоятельная работа
**Цель: провести регрессионный анализ между зависимой величиной цены на ноутбуки от их фактической стоимости**

Источник - Kaggle, ссылка - https://www.kaggle.com/datasets/mohidabdulrehman/laptop-price-dataset
```{r}
data <- read.csv(file = "laptop_data.csv")
```

Разделим выборку на тестовую и обучающую.
```{r}
set.seed(56)

split <- sample.split(data$Price, SplitRatio = 0.75)

train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
```

Построим модель линейной регрессии. В качестве зависимой переменной
выступает – Price, независимой – Ram. Выводим полную информацию о построенной модели.
```{r}
model_1 <- lm(data=train, Price ~ Ram)

summary(model_1)
```

Согласно полученным результатам уравнение регрессии имеет вид:
Price = 41.91 + 1.67*Ram

Проверим линейную связь
F-критерий
H0: a=b 0 , (т.е. линейная связь между x и y отсутствует);
H1: a>0 или b>0 (т.е. наличие линейной связи).

```{r}
mean_model <- mean(train$Price)
f <- sum((model_1$fitted.values - mean_model)^2) / summary(model_1)$sigma^2
f

f_tabl <- qf(0.95, 1, nrow(train)-2)
f_tabl
```

| F расч | > F табл => отвергаем H0 в пользу наличия линейной связи с вероятностью 0.95.


Находим коэффициенты детерминации:
```{r}
#коэффициент множественной корреляции
summary(model_1)$r.squared 

#квадрат коэфициента скоректированной корреляции 
summary(model_1)$adj.r.squared 
```

Находим остаточную дисперсию:
```{r}
summary(model_1)$sigma^2
```

Средняя ошибка аппроксимации 
```{r}
A <- sum(abs((train$Price - model_1$fitted.values)/train$Price)) / nrow(train) * 100
str(A)
```

А > 5-7% => качество модели плохое

Применив функцию glance(), можно также найти вышеописанные параметры:

```{r}
glance(model_1)
```

Удалим незначащий фактор.
Построим модель линейной регрессии.
```{r}
model_1 <- lm(data=train, Price ~ Ram - 1)

summary(model_1)
```

Согласно полученным результатам уравнение регрессии имеет вид:
Price = 41.91 + 1.67*Ram

Проверим линейную связь
F-критерий
H0: a=b 0 , (т.е. линейная связь между x и y отсутствует);
H1: a>0 или b>0 (т.е. наличие линейной связи).

```{r}
mean_model <- mean(train$Price)
f <- sum((model_1$fitted.values - mean_model)^2) / summary(model_1)$sigma^2
f

f_tabl <- qf(0.95, 1, nrow(train)-2)
f_tabl
```

| F расч | > F табл => отвергаем H0 в пользу наличия линейной связи с вероятностью 0.95.


Находим коэффициенты детерминации:
```{r}
#коэффициент множественной корреляции
summary(model_1)$r.squared 

#квадрат коэфициента скоректированной корреляции 
summary(model_1)$adj.r.squared 
```

Находим остаточную дисперсию:
```{r}
summary(model_1)$sigma^2
```

Средняя ошибка аппроксимации 
```{r}
A <- sum(abs((train$Price - model_1$fitted.values)/train$Price)) / nrow(train) * 100
str(A)
```

А > 5-7% => качество модели плохое

### Проверим условия для получения состоятельных, несмещенных, эффективных оценок

Проверка случайности остаточной компоненты. Построим график зависимости остатков от спрогнозированных значений модели

```{r}
qplot(y = model_1$fitted.values, x = model_1$residuals, xlab = "Остаточные степени свободы, Ei", ylab="Спрогнозированные значения, y^")
```

Проверим условие M(Ei) = 0.

H0: M(Ei) = 0(математическое ожидание остатков равно нулю);
H1: M(Ei) != 0(математическое ожидание остатков отлично от нуля).

```{r}
mean(model_1$residuals)
```

Вычисляем t расч.:

```{r}
a<-mean(model_1$residuals)
b<-sd(model_1$residuals, na.rm = FALSE)
n <- sqrt(nrow(train))

tm <- a/b*n
str(tm)
```

Вычисляем t табл. при p=0.95 и степени свободы N-1:


```{r}
df <- nrow(train)

qt(0.95, df - 1)
```
|t расч.| > t табл. => отвергаем H0 с вероятностью p=0.95.

Протестируем на наличие гетероскедастичности в остатках регрессионное уравнение с помощью теста Бройша-Погана:
H0: D(Ei) = sig^2 (отсутствие гетероскедастичности, наличие гомоскедастичности)
H1: D(Ei) != sig^2 (наличие гетероскедастичности)

```{r}
#bptest(model_1)
```

Так как значение p-value больше 0.05, нулевая ги
потеза об отсутствие гетероскедастичности остатков принимается.


Наличие гетероскедастичности в остатках регрессии можно проверить с помощью теста ранговой корреляции Спирмена. 

Суть теста заключается в определении наличия связи между ростом остаточной компоненты и ростом независимого фактора, то есть определение роста дисперсии остатков. Такая зависимость проверяется на основе расчета коэффициента ранговой корреляции Спирмена ρ между остатками модели E и независимым фактором Price.
```{r}
cor.test (train$Price, model_1$residuals, method = "spearman")
```

Так как значение p-value меньше 0.05, нулевая гипотеза об отсутствие гетероскедастичности остатков отвергается.


Проверим условие cov(Ei,Ej)=0, i!=j

Н0: rho=0 (т.е. автокорреляция остатков отсутствует);
H1: rho>0 или rho<0 (наличие положительной или отрицательной автокорреляции остатков). 

```{r}
# тест Дарбина-Уотсона
  bgtest(model_1)

# тест Бройша- Годфри
dwtest(model_1)
```
Так как значение p-value больше 0.05 => гипотеза H0 об отсутствии автокорреляции остатков принимается


Проверим условие Ei ~ N(0, sig^2), т.е. согласуются ли остатки регрессии с нормальным законом:

H0: остатки регрессии согласуются с нормальным законом распределения
H1: остатки регрессии не согласуются с нормальным законом распределения

Рассмотрим графические тесты:

```{r}
qqnorm(model_1$residuals)
```

```{r}
library(sm);
Z <- model_1$residuals
hist(Z, main = "Гистограмма остатков")

sm.density(model_1$residuals, model = "Normal",xlab = "Остатки", ylab = "Функция плотности распределения")
```

Рассмотрим параметрические тесты:

```{r}
library(nortest)

# тест Lilliefors (Kolmogorov-Smirnov) 
lillie.test(model_1$residuals)
```

Так как значение p-value меньше 0.05, нулевая гипотеза о согласии распределения остатков с нормальным законом распределения отвергается.

Рассмотрим также тест Шапиро-Уилка. 

```{r}
# тест Шапиро-Уилка
sh <- model_1$residuals
#View(sh)
shapiro.test(sh)
```

Так как значение p-value меньше 0.05, нулевая гипотеза о согласии распределения остатков с нормальным законом распределения отвергается.

Прогнозирование значений по полученной модели на тестовой выборке:

```{r}
plot(data$Ram, data$Price, ylab="Ликвидированые организации", xlab="Зарегистрированные организации")
lines(data$Ram, predict(model_1, data), col = 'red')
```




